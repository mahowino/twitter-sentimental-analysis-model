{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a5c36a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import re\n",
    "import multiprocessing\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32916932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the names of the columns into col_names\n",
    "\n",
    "col_names = [\"target\", \"ids\", \"date\", \"flag\", \"user\", \"text\"]\n",
    "# reading the data from the path and using ISO-8859-1 encoding to decode it.\n",
    "\n",
    "df = pd.read_csv('input/tweetsdata.csv',\n",
    "            encoding = \"ISO-8859-1\",\n",
    "            names=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cc1e70e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target         ids                          date      flag  \\\n",
       "0       0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "\n",
       "              user                                               text  \n",
       "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1    scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2         mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3          ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4           Karoli  @nationwideclass no, it's not behaving at all....  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f9870ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75279</th>\n",
       "      <td>0</td>\n",
       "      <td>1695109631</td>\n",
       "      <td>Mon May 04 05:13:48 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>tigrous4ever</td>\n",
       "      <td>@pixieoncb haha WTF that is very random of Mrs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1171237</th>\n",
       "      <td>4</td>\n",
       "      <td>1980467897</td>\n",
       "      <td>Sun May 31 06:49:56 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>pvesey</td>\n",
       "      <td>Good morning everyone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584283</th>\n",
       "      <td>0</td>\n",
       "      <td>2215224130</td>\n",
       "      <td>Wed Jun 17 17:50:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>BastaYaGuate</td>\n",
       "      <td>and excuses by the writing but I do not speak ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886335</th>\n",
       "      <td>4</td>\n",
       "      <td>1686707249</td>\n",
       "      <td>Sun May 03 06:29:08 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>c_cooper88</td>\n",
       "      <td>@alibelle yes thanks  why am I very odd then?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257244</th>\n",
       "      <td>4</td>\n",
       "      <td>1997674986</td>\n",
       "      <td>Mon Jun 01 17:15:44 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>AlannaLessThan3</td>\n",
       "      <td>My favorite mascara finally dried up..*cry*. B...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         target         ids                          date      flag  \\\n",
       "75279         0  1695109631  Mon May 04 05:13:48 PDT 2009  NO_QUERY   \n",
       "1171237       4  1980467897  Sun May 31 06:49:56 PDT 2009  NO_QUERY   \n",
       "584283        0  2215224130  Wed Jun 17 17:50:53 PDT 2009  NO_QUERY   \n",
       "886335        4  1686707249  Sun May 03 06:29:08 PDT 2009  NO_QUERY   \n",
       "1257244       4  1997674986  Mon Jun 01 17:15:44 PDT 2009  NO_QUERY   \n",
       "\n",
       "                    user                                               text  \n",
       "75279       tigrous4ever  @pixieoncb haha WTF that is very random of Mrs...  \n",
       "1171237           pvesey                             Good morning everyone   \n",
       "584283      BastaYaGuate  and excuses by the writing but I do not speak ...  \n",
       "886335        c_cooper88      @alibelle yes thanks  why am I very odd then?  \n",
       "1257244  AlannaLessThan3  My favorite mascara finally dried up..*cry*. B...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(160000) # taking 160k rows from the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e8f49ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 160000 entries, 75279 to 1505125\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   target  160000 non-null  int64 \n",
      " 1   ids     160000 non-null  int64 \n",
      " 2   date    160000 non-null  object\n",
      " 3   flag    160000 non-null  object\n",
      " 4   user    160000 non-null  object\n",
      " 5   text    160000 non-null  object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 8.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info() # shows the columns, and their types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6109c9f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160000, 6)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32835aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target']=df['target'].replace(4,1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e4c7173",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df['text']\n",
    "labels = np.array(df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f20b030b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Good morning everyone '"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[1] # displaying a row of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "700b5917",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = set(stopwords.words('english'))\n",
    "punctuation = list(string.punctuation)\n",
    "stop.update(punctuation)\n",
    "\n",
    "#Removing the stopwords from text\n",
    "def split_into_words(text):\n",
    "    # split into words by white space\n",
    "    words = text.split()\n",
    "    return words\n",
    "\n",
    "def to_lower_case(words):\n",
    "    # convert to lower case\n",
    "    words = [word.lower() for word in words]\n",
    "    return words\n",
    "\n",
    "def remove_punctuation(words):\n",
    "    # prepare regex for char filtering\n",
    "    re_punc = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "    # remove punctuation from each word\n",
    "    stripped = [re_punc.sub('', w) for w in words]\n",
    "    return stripped\n",
    "\n",
    "def keep_alphabetic(words):\n",
    "    # remove remaining tokens that are not alphabetic\n",
    "    words = [word for word in words if word.isalpha()]\n",
    "    return words\n",
    "\n",
    "def remove_stopwords(words):\n",
    "    # filter out stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "    return words\n",
    "\n",
    "def to_sentence(words):\n",
    "    # join words to a sentence\n",
    "    return ' '.join(words)\n",
    "def tweet(words):\n",
    "    tweet_tokenizer = nltk.tokenize.TweetTokenizer(strip_handles=True,reduce_len=True)\n",
    "    tweet = tweet_tokenizer.tokenize(words)\n",
    "    return tweet\n",
    "        \n",
    "\n",
    "#Removing the noisy text\n",
    "def denoise_text(text):\n",
    "    words = split_into_words(text)\n",
    "    words = to_lower_case(words)\n",
    "    words = remove_punctuation(words)\n",
    "    words = keep_alphabetic(words)\n",
    "    words = remove_stopwords(words)\n",
    "    return to_sentence(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb980776",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.apply(denoise_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1535cfd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: ['@pixieoncb haha WTF that is very random of Mrs Vall but then again you were quite sick ', 'Good morning everyone ']\n",
      "---\n",
      "After: ['pixieoncb haha wtf random mrs vall quite sick', 'good morning everyone']\n"
     ]
    }
   ],
   "source": [
    "print('Before: {}'. format(list(df['text'][:2])))\n",
    "print('---')\n",
    "print('After: {}'. format(list(data[:2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5bb1bf6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split in training validation and test sets\n",
    "X_train, X_test, y_train, y_test = test = train_test_split(data, labels,test_size=0.20,\n",
    "                                                           random_state=1,\n",
    "                                                           stratify = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "297e0a60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116369"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets take 10k words in num_words\n",
    "tokenizer = Tokenizer(num_words=10000, oov_token = '<OOV>')\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "word_index = tokenizer.word_index\n",
    "VOCAB_SIZE = len(word_index)+1\n",
    "VOCAB_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c30dabaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = max([len(x) for x in X_train]) # return 175 which is too big for tweets data.\n",
    "maxlen = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4df2fb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "train_padded_sequences = pad_sequences(train_sequences,maxlen=maxlen,padding='post',truncating='post')\n",
    "test_sequences = tokenizer.texts_to_sequences(X_test)\n",
    "test_padded_sequences = pad_sequences(test_sequences,maxlen=maxlen,padding='post',truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c27bc10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_padded_sequences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "97b54fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "93b7b07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(VOCAB_SIZE+1, embedding_dim, input_length=maxlen),\n",
    "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(16)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.30),\n",
    "        tf.keras.layers.Dense(embedding_dim,activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.30),\n",
    "        tf.keras.layers.Dense(8,activation='relu'),\n",
    "        tf.keras.layers.Dense(1,activation='sigmoid'),\n",
    "    ])\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy',\n",
    "                optimizer = 'adam',\n",
    "                metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f6066ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 50, 32)            3723840   \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 32)               6272      \n",
      " l)                                                              \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 32)                0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 32)               128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                1056      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 32)               128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 264       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,731,697\n",
      "Trainable params: 3,731,569\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8851c86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "4000/4000 [==============================] - 423s 104ms/step - loss: 0.5472 - accuracy: 0.7239 - val_loss: 0.7300 - val_accuracy: 0.6223\n",
      "Epoch 2/3\n",
      "4000/4000 [==============================] - 495s 124ms/step - loss: 0.4816 - accuracy: 0.7712 - val_loss: 0.4810 - val_accuracy: 0.7673\n",
      "Epoch 3/3\n",
      "4000/4000 [==============================] - 601s 150ms/step - loss: 0.4536 - accuracy: 0.7864 - val_loss: 0.4822 - val_accuracy: 0.7681\n"
     ]
    }
   ],
   "source": [
    "history =    model.fit(train_padded_sequences,\n",
    "                                               y_train,\n",
    "                                               validation_data = (test_padded_sequences, y_test),\n",
    "                                               epochs = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cabdb684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ohken pity walmart around corner every walmart germany closed label: ; 0\n"
     ]
    }
   ],
   "source": [
    "print(X_test.iloc[9],'label: ;',y_test[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0e31759a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "keras_file='models/SavedModel.h5'\n",
    "keras_path=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "178184ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.models.save_model(model, keras_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "51fff9a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_13_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses, lstm_cell_14_layer_call_fn, lstm_cell_14_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\USER\\AppData\\Local\\Temp\\tmp8wcjwxj_\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\USER\\AppData\\Local\\Temp\\tmp8wcjwxj_\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3751440"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!pip3 install h5py\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "model = keras.models.load_model(keras_file)\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.experimental_new_converter=True\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,\n",
    "tf.lite.OpsSet.SELECT_TF_OPS]\n",
    "\n",
    "tfmodel = converter.convert()\n",
    "open('sentimental_model.tflite', 'wb').write(tfmodel)\n",
    "#import tensorflow as tf\n",
    "\n",
    "# Convert the model\n",
    "#converter = tf.lite.TFLiteConverter.from_saved_model('models') # path to the SavedModel directory\n",
    "#tflite_model = converter.convert()\n",
    "#open('model.tflite', 'wb').write(tflite_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19541b4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
